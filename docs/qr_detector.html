<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>QR Detector · Visionlab</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="## Introduction"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="QR Detector · Visionlab"/><meta property="og:type" content="website"/><meta property="og:url" content="https://visiont3lab.github.io/documentation/"/><meta property="og:description" content="## Introduction"/><meta property="og:image" content="https://visiont3lab.github.io/documentation/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://visiont3lab.github.io/documentation/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/documentation/img/favicon.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/monokai.min.css"/><link rel="alternate" type="application/atom+xml" href="https://visiont3lab.github.io/documentation/blog/atom.xml" title="Visionlab Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://visiont3lab.github.io/documentation/blog/feed.xml" title="Visionlab Blog RSS Feed"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,700"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/documentation/js/scrollSpy.js"></script><link rel="stylesheet" href="/documentation/css/main.css"/><script src="/documentation/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/documentation/"><img class="logo" src="/documentation/img/favicon.ico" alt="Visionlab"/><h2 class="headerTitleWithLogo">Visionlab</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/documentation/docs/deep_learning_setup_guide" target="_self">Docs</a></li><li class=""><a href="/documentation/docs/docker_setup_guide" target="_self">API</a></li><li class=""><a href="/documentation/help" target="_self">Help</a></li><li class=""><a href="/documentation/blog/" target="_self">Blog</a></li><li class=""><a target="_self"></a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Research</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Installation Setup and useful scripts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/documentation/docs/deep_learning_setup_guide">Deep Learning Setup Guide</a></li><li class="navListItem"><a class="navItem" href="/documentation/docs/installation_and_samples_scripts">Installation Scripts</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Research</h3><ul class=""><li class="navListItem"><a class="navItem" href="/documentation/docs/overview">Overview</a></li><li class="navListItem"><a class="navItem" href="/documentation/docs/photometry">Photometry</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/documentation/docs/qr_detector">QR Detector</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/visiont3lab/documentation/edit/master/docs/qr_detector.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 class="postHeaderTitle">QR Detector</h1></header><article><div><span><h2><a class="anchor" aria-hidden="true" id="introduction"></a><a href="#introduction" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Introduction</h2>
<p>In this report we focused our attention on how to detect and extract QR data. In doing this we focused our attention on the <a href="http://zbar.sourceforge.net/">zbar</a> library.  In particular we have tested the qr code detector in python using the pyzbar package and on c++ using the zbar library available on the remote (apt install libzbar-dev).</p>
<p>We are interested in real time application and for this reason we have build a simple docker <a href="https://www.ros.org/">ROS</a> setup. The latter contains the usb_cam node (to get raw image from a camera) and the QR detector node in charge of detecting the QR and display the result. We have build a result image called &quot;image_result&quot; that is shown automatically using image_view.</p>
<h2><a class="anchor" aria-hidden="true" id="setup"></a><a href="#setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup</h2>
<h3><a class="anchor" aria-hidden="true" id="run-python-qr-detector"></a><a href="#run-python-qr-detector" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Run python qr detector</h3>
<p>It works with both pytho2 and python3.</p>
<pre><code class="hljs"><span class="hljs-keyword">cd</span> qr_reader_python
pip install pyzbar opencv-<span class="hljs-keyword">python</span> numpy 
<span class="hljs-keyword">python</span> qr_reader_opencv.<span class="hljs-keyword">py</span>
<span class="hljs-built_in">or</span>
<span class="hljs-keyword">python</span> qr_reader_pyzbar.<span class="hljs-keyword">py</span>
</code></pre>
<p>We have notice that the pyzbar implementation is able to detect the qr at larger distance than the opencv one.</p>
<h3><a class="anchor" aria-hidden="true" id="run-cpp-qr-detector"></a><a href="#run-cpp-qr-detector" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Run cpp qr detector</h3>
<p>C++ implementation based on <a href="https://www.learnopencv.com/opencv-qr-code-scanner-c-and-python/">this example</a></p>
<pre><code class="hljs"><span class="hljs-keyword">cd</span> qr_reader_cpp
mdkir -p build
<span class="hljs-keyword">cd</span> build
cmake <span class="hljs-string">..</span>
make
<span class="hljs-string">./run_qr_reader</span>
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="run-docker-ros-container-usb_cam-qr_detector"></a><a href="#run-docker-ros-container-usb_cam-qr_detector" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Run docker ros container (usb_cam + qr_detector)</h3>
<p>Setup ROS workspace using docker.  More information are available at <a href="https://tuw-cpsg.github.io/tutorials/docker-ros/">Docker with ROS</a>
For this example we will use ros melodic that is usually connected to Ubuntu 18.04 LTS. We will also use python2.7 beacause ROS support only this one.
In running the docker container we will mount the volume &quot;qr_reader_ros&quot; that will be our R0S workspace.</p>
<p>Set X Server host permissions.  More information available <a href="http://wiki.ros.org/docker/Tutorials/GUI">here</a></p>
<pre><code class="hljs">xhost +<span class="hljs-keyword">local</span>:docker 
</code></pre>
<p>Run docker ros docker container with sudo to give device permission <a href="https://medium.com/@zwinny/docker-using-webcam-9fafb26cf1e6">device-docker</a>.</p>
<pre><code class="hljs">sudo docker run \
    -<span class="ruby">it \
</span>    -<span class="ruby">-name ros_qr_demo  \
</span>    -<span class="ruby">v $HOME/visiont3lab-github/qr_reader/qr_reader_ros_ws/<span class="hljs-symbol">src:</span>/root/catkin_ws/src/ \
</span>    -<span class="ruby">-env DISPLAY=$DISPLAY \
</span>    -<span class="ruby">v <span class="hljs-string">"/tmp/.X11-unix:/tmp/.X11-unix:rw"</span> \
</span>    -<span class="ruby">-network host \
</span>    -<span class="ruby">-env ROS_MASTER_URI=<span class="hljs-symbol">http:</span>/<span class="hljs-regexp">/localhost:11311 \
</span></span>    -<span class="ruby"><span class="hljs-regexp">-device=/dev</span><span class="hljs-regexp">/video0:/dev</span><span class="hljs-regexp">/video0 \
</span></span>    ros:melodic-perception-bionic /bin/bash
</code></pre>
<p>After having started the container we need to install the <a href="http://wiki.ros.org/usb_cam">usb_cam</a> package that will allow to communicate with a camera.
To do this inside the container we need to do:</p>
<pre><code class="hljs"><span class="hljs-attr">apt</span> <span class="hljs-string">update</span>
<span class="hljs-attr">apt</span> <span class="hljs-string">install -y ros-melodic-usb-cam python-pip libzbar-dev vim</span>
<span class="hljs-attr">pip</span> <span class="hljs-string">install pyzbar</span>

</code></pre>
<p>Now we only need to compile and run. We assume that you a camera connected to your pc.</p>
<ol>
<li><p>Compile workspace and start roscore</p>
<pre><code class="hljs">source <span class="hljs-meta-keyword">/opt/</span>ros<span class="hljs-meta-keyword">/melodic/</span>devel/setup.bash
cd <span class="hljs-meta-keyword">/root/</span>catkin_ws/
catkin_make
roscore
</code></pre></li>
<li><p>Run USB Cam package</p>
<p>Open a new terminal inside the docker container and run the usb_cam node</p>
<pre><code class="hljs"><span class="hljs-symbol">docker</span> exec -<span class="hljs-keyword">it </span>ros_qr_demo /<span class="hljs-keyword">bin/bash
</span><span class="hljs-symbol">source</span> /<span class="hljs-meta">opt</span>/ros/melodic/devel/setup.<span class="hljs-keyword">bash
</span><span class="hljs-symbol">roslaunch</span> usb_cam usb_cam-test.launch
</code></pre>
<p>The usb_cam-test.launch file is located at &quot;/opt/ros/melodic/share/usb_cam/launch/usb_cam-test.launch&quot; . You can modify it as you like.</p></li>
<li><p>Run QR Detector package (Open a new terminal (new instance of docker container))</p>
<p>Open a new terminal inside the docker container and run the qr detector
Before running this it is required that usb_cam node is started. Wait until you see /usb_cam/image_raw is displayed</p>
<pre><code class="hljs">docker exec -it ros_qr_demo <span class="hljs-regexp">/bin/</span>bash
<span class="hljs-keyword">source</span> <span class="hljs-regexp">/root/</span>catkin_ws<span class="hljs-regexp">/devel/</span>setup.bash
roslaunch qr_detecor qr_detector.launch
</code></pre></li>
</ol>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/documentation/docs/photometry"><span class="arrow-prev">← </span><span>Photometry</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#introduction">Introduction</a></li><li><a href="#setup">Setup</a><ul class="toc-headings"><li><a href="#run-python-qr-detector">Run python qr detector</a></li><li><a href="#run-cpp-qr-detector">Run cpp qr detector</a></li><li><a href="#run-docker-ros-container-usb_cam-qr_detector">Run docker ros container (usb_cam + qr_detector)</a></li></ul></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/documentation/" class="nav-home"><img src="/documentation/img/favicon.ico" alt="Visionlab" width="66" height="58"/></a><div><h5>Docs</h5><a href="/documentation/docs/en/doc1.html">Getting Started (or other categories)</a><a href="/documentation/docs/en/doc2.html">Guides (or other categories)</a><a href="/documentation/docs/en/doc3.html">API Reference (or other categories)</a></div><div><h5>Community</h5><a href="/documentation/en/users.html">User Showcase</a><a href="https://stackoverflow.com/questions/tagged/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://discordapp.com/">Project Chat</a><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="/documentation/blog">Blog</a><a href="https://github.com/">GitHub</a><a class="github-button" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/documentation/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2019 Your Name or Your Company Name</section></footer></div></body></html>